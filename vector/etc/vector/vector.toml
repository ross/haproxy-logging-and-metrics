[api]
  enabled = true
  address = "0.0.0.0:8686"

[sources.haproxy]
  type = "syslog"
  address = "0.0.0.0:514"
  mode = "udp"

# Mark each message with an initial type for routing
[transforms.mark_log_type]
  type = "remap"
  inputs = ["haproxy"]
  source = '''
if contains!(.message, "bytes_rx=") {
  .log_type = "request"
} else if contains!(.message, " check for ") {
  .log_type = "health_check"
} else if ends_with!(.message, " remaining in queue.") {
  .log_type = "health_status"
} else if ends_with!(.message, " no server available!") {
  .log_type = "health_down"
} else {
  .log_type = "misc"
}
'''

[transforms.log_type]
  type = "route"
  inputs = ["mark_log_type"]
  route.request = '.log_type == "request"'
  route.health_check = '.log_type == "health_check"'
  route.health_status = '.log_type == "health_status"'
  route.health_down = '.log_type == "health_down"'
  route.misc = '.log_type == "misc"'

[transforms.parse_request]
  type = "remap"
  inputs = ["log_type.request"]
  source = '''
# try and parse logfmt, we're ok with it failing and even expect it to for healthchecks and other non-connect/request messages
., err = parse_key_value(.message)
if err == null {
  ## type conversion & data cleanup

  if exists(.bytes_rx) {
    .bytes_rx = to_int(.bytes_rx) ?? .bytes_rx
  }

  if exists(.bytes_tx) {
    .bytes_tx = to_int(.bytes_tx) ?? .bytes_tx
  }

  if exists(.client_port) {
    .client_port = to_int(.client_port) ?? .client_port
  }

  if .fc_reordering == "-" {
    .fc_reordering = null
  } else if exists(.fc_reordering) {
    .fc_reordering = to_int(.fc_reordering)
  }

  if .fc_retrans == "-" {
    .fc_retrans = null
  } else if exists(.fc_retrans) {
    .fc_retrans = to_int(.fc_retrans)
  }

  if .fc_rtt == "-" {
    .fc_rtt = null
  } else if exists(.fc_rtt) {
    .fc_rtt = to_int(.fc_rtt)
  }

  if .fc_rttvar == "-" {
    .fc_rttvar = null
  } else if exists(.fc_rttvar) {
    .fc_rttvar = to_int(.fc_rttvar)
  }

  if exists(.frontend_port) {
    .frontend_port = to_int(.frontend_port) ?? .frontend_port
  }

  if .host_header == "" {
    .host_header = null
  }

  if .real_ip == "-" {
    .real_ip = null
  }

  if exists(.retries) {
    .retries = to_int(.retries) ?? .retries
  }

  if .ssl_ciphers == "-" {
    .ssl_ciphers = null
  }

  if .ssl_version == "-" {
    .ssl_version = null
  }

  if .status_code == "-1" {
    .status_code = null
  } else if exists(.status_code) {
    .status_code = to_int(.status_code)
    # nested if b/c of this bug https://github.com/timberio/vector/issues/8284
    .status_class = if .status_code < 200 {
      "1xx"
    } else {
      if .status_code < 300 {
        "2xx"
      } else {
        if .status_code < 400 {
          "3xx"
        } else {
          if .status_code < 500 {
            "4xx"
          } else {
            "5xx"
          }
        }
      }
    }
  }

  if .time_backend_connect == "-1" {
    .time_backend_connect = null
  } else if exists(.time_backend_connect) {
    .time_backend_connect = to_int(.time_backend_connect)
  }

  if .time_backend_response == "-1" {
    .time_backend_response = null
  } else if exists(.time_backend_response) {
    .time_backend_response = to_int(.time_backend_response)
  }

  if exists(.time_connect) {
    .time_connect = to_int(.time_connect) ?? .time_connect
  }

  if exists(.time_idle) {
    .time_idle = to_int(.time_idle) ?? .time_idle
  }

  if .time_request == "-1" {
    .time_request = null
  } else if exists(.time_request) {
    .time_request = to_int(.time_request)
  }

  if .time_response == "-1" {
    .time_response = null
  } else if exists(.time_response) {
    .time_response = to_int(.time_response)
  }

  if exists(.time_start) {
    .time_start = to_int(.time_start) ?? .time_start
  }

  if exists(.time_total) {
    .time_total = to_int(.time_total) ?? .time_total
  }

  if exists(.time_user_est) {
    .time_user_est = to_int(.time_user_est) ?? .time_user_est
  }

  if .time_waiting == "-1" {
    .time_waiting = null
  } else if exists(.time_waiting) {
    .time_waiting = to_int(.time_waiting)
  }

  if .user_agent == "" {
    .user_agent = null
  }

  # Refine log_type
  if exists(.ssl_version) {
    .log_type = "https"
  } else if exists(.request_id) {
    .log_type = "http"
  } else {
    .log_type = "tcp"
  }
}
'''

[transforms.request_type]
  type = "route"
  inputs = ["parse_request"]
  route.tcp = '.log_type == "tcp"'
  route.http = '.log_type == "http"'
  route.https = '.log_type == "https"'

# Things that only make sense for tcp connections
# Nothing at this point...
#[transforms.metric_tcp]

# Things that only make sense for https connections
[transforms.metric_https]
  type = "log_to_metric"
  inputs = ["request_type.https"]

  [[transforms.metric_https.metrics]]
    field = "ssl_version"
    name = "ssl"
    namespace = "haproxy"
    type = "counter"

    tags.backend_name = "{{backend_name}}"
    tags.frontend_name = "{{frontend_name}}"
    tags.frontend_port = "{{frontend_port}}"
    tags.ssl_version = "{{ssl_version}}"
    tags.ssl_ciphers = "{{ssl_ciphers}}"

# Things that make sense for http(s) connections
[transforms.metric_http]
  type = "log_to_metric"
  inputs = ["request_type.http", "request_type.https"]

  [[transforms.metric_http.metrics]]
    field = "time_response"
    name = "time_response"
    namespace = "haproxy"
    type = "histogram"

    tags.backend_name = "{{backend_name}}"
    tags.frontend_name = "{{frontend_name}}"
    tags.frontend_port = "{{frontend_port}}"
    tags.method = "{{method}}"
    tags.status_class = "{{status_class}}"

  [[transforms.metric_http.metrics]]
    field = "version"
    name = "version"
    namespace = "haproxy"
    type = "counter"

    tags.backend_name = "{{backend_name}}"
    tags.frontend_name = "{{frontend_name}}"
    tags.frontend_port = "{{frontend_port}}"

# Things that make sense for all connections
[transforms.metric_all]
  type = "log_to_metric"
  inputs = ["request_type.tcp", "request_type.http", "request_type.https"]

  [[transforms.metric_all.metrics]]
    field = "bytes_rx"
    increment_by_value = true
    name = "bytes_rx"
    namespace = "haproxy"
    type = "histogram"

    tags.backend_name = "{{backend_name}}"
    tags.frontend_name = "{{frontend_name}}"
    tags.frontend_port = "{{frontend_port}}"
    tags.termination_state = "{{termination_state}}"

  [[transforms.metric_all.metrics]]
    field = "bytes_tx"
    increment_by_value = true
    name = "bytes_tx"
    namespace = "haproxy"
    type = "histogram"

    tags.backend_name = "{{backend_name}}"
    tags.frontend_name = "{{frontend_name}}"
    tags.frontend_port = "{{frontend_port}}"
    tags.termination_state = "{{termination_state}}"

  [[transforms.metric_all.metrics]]
    field = "time_backend_connect"
    increment_by_value = true
    name = "time_backend_connect"
    namespace = "haproxy"
    type = "histogram"

    tags.backend_name = "{{backend_name}}"
    tags.termination_state = "{{termination_state}}"

  [[transforms.metric_all.metrics]]
    field = "time_total"
    increment_by_value = true
    name = "time_total"
    namespace = "haproxy"
    type = "histogram"

    tags.backend_name = "{{backend_name}}"
    tags.frontend_name = "{{frontend_name}}"
    tags.frontend_port = "{{frontend_port}}"
    tags.termination_state = "{{termination_state}}"

  [[transforms.metric_all.metrics]]
    field = "time_user_est"
    increment_by_value = true
    name = "time_user_est"
    namespace = "haproxy"
    type = "histogram"

    tags.backend_name = "{{backend_name}}"
    tags.frontend_name = "{{frontend_name}}"
    tags.frontend_port = "{{frontend_port}}"
    tags.termination_state = "{{termination_state}}"

# Health check for server httpbin/nghttp2 succeeded, reason: Layer7 check passed, code: 200, check duration: 362ms, status: 3/3 UP.
# Health check for server httpbin/nghttp3 failed, reason: Layer4 timeout, check duration: 15002ms, status: 0/2 DOWN.
# Health check for server tcpchecks/nghttp2 failed, reason: Layer7 invalid response, info: "TCPCHK got an empty response at step 2", check duration: 189ms, status: 0/2 DOWN.
# Health check for server tcpchecks/nghttp3 failed, reason: Layer4 timeout, info: " at initial connection step of tcp-check", check duration: 15008ms, status: 0/2 DOWN.
#
# Relivant code bits are found at:
# https://github.com/haproxy/haproxy/blob/6a510907807b7fb901654b4f5e5100aa91868fb7/src/check.c#L524-L544
# https://github.com/haproxy/haproxy/blob/6a510907807b7fb901654b4f5e5100aa91868fb7/src/server.c#L1325-L1381
# https://github.com/haproxy/haproxy/blob/6a510907807b7fb901654b4f5e5100aa91868fb7/src/server.c#L1340-L1359
# https://github.com/haproxy/haproxy/blob/6a510907807b7fb901654b4f5e5100aa91868fb7/src/check.c#L317-L348
#
# Going to break this up to avoid a single mega-regex from a
# readability/maintainability standpoint. It'll probably be a less performant,
# but these shouldn't be THAT high volume in most cases. Once they're all
# sorted/working maybe we can explore combining them if it makes sense.
[transforms.parse_health_check]
  type = "remap"
  inputs = ["log_type.health_check"]
  source = '''
## Initial "check for", backend, server and result
. |= parse_regex!(.message, r'^(?P<type>Health|Agent) check for (?P<backup>backup )?server (?P<backend>[\w\-]+)/(?P<server>[\w\-]+) (conditionally )?(?P<result>succeeded|failed)')

# reason, code
. |= parse_regex(.message, r', reason: (?P<reason>[^,]+)(, code: (?P<code>\d+))?') ?? {}

# info
. |= parse_regex(.message, r', info: "(?P<info>[^"]+)",') ?? {}

# duration
. |= parse_regex(.message, r', check duration: (?P<duration>\d+)ms') ?? {}

# status
. |= parse_regex(.message, r', status: (?P<count>\d+)/(?P<of>\d+) (?P<status>UP|DRAIN|DOWN)') ?? {}
'''

# Server httpbin/nghttp3 is DOWN. 1 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.
# Server tcpchecks/nghttp2 is DOWN. 1 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.
[transforms.parse_health_status]
  type = "remap"
  inputs = ["log_type.health_status"]
  source = '''
. |= parse_regex!(.message, r'^Server (?P<backend>[\w\-]+)/(?P<server>[\w\-]+) is (?P<status>UP|DOWN)\. (?P<active>\d+) active and (?P<backup>\d+) backup servers left. (?P<sessions_active>\d+) sessions active, (?P<sessions_requeued>\d+) requeued, (?P<sessions_remaining>\d+) remaining in queue.')
'''

[transforms.parse_health_down]
  type = "remap"
  inputs = ["log_type.health_down"]
  source = '''
. |= parse_regex!(.message, r'^backend (?P<backend>[\w\-]+) has no server available!')
'''

[sinks.datadog_logs]
  type = "datadog_logs"
  inputs = ["log_type.misc", "parse*"]
  default_api_key = "${DATADOG_API_KEY}"
  [sinks.datadog_logs.encoding]
    codec = "json"

# TODO: once aggregate is in the released version
#[transforms.aggregate_metric]
#  type = "aggregate"
#  inputs = ["metric*"]
#  interval_ms = 10000

[sinks.datadog_metric]
  type = "datadog_metrics"
  inputs = ["metric*"]
  api_key = "${DATADOG_API_KEY}"

[sinks.stdout]
  type = "console"
  inputs = ["parse_request"]
  target = "stdout"
  encoding.codec = "json"
